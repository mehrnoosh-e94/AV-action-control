{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6b27ae-4bbd-4dff-a8a7-332ec166218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import variables_CAI as var\n",
    "import functions_CAI as func\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8ce76-9cef-4d23-997e-50915cebf1e1",
   "metadata": {},
   "source": [
    "Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d8ba1f-ff41-4f6f-b543-a243fa8a654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Y = var.T_Y  #timing for yellow phase\n",
    "T_G = var.T_G #timing for green phase\n",
    "T_R = var.T_R #timing for red phase\n",
    "total_T = T_Y + T_G + T_R\n",
    "\n",
    "d_lower = var.d_lower #lower bound for the initial distribution of distance\n",
    "d_upper = var.d_upper #upper bound for the initial distribution of distance\n",
    "v_lower = var.v_lower #lower bound for the initial distribution of velocity\n",
    "v_upper = var.v_upper #upper bound for the initial distribution of velocity\n",
    "\n",
    "delta_t = var.delta_t\n",
    "\n",
    "phi_to_T_dict = {'Y': T_Y, 'G': T_G, 'R': T_R} #dictionary to map each phase to its timing\n",
    "phi_to_next_phi_dict = {'G':'Y', 'Y':'R', 'R':'G'} #dictionary to map each phase to its next phase\n",
    "phi_prev_phi_dict = var.phi_prev_phi_dict #dictionary to map each phase to its previous phase\n",
    "\n",
    "std_d= 0.5#var.std_d #standard deviation of distance noise in state process\n",
    "std_v= 0.25#var.std_v #standard deviation of velocity noise in state process\n",
    "std_t_phi= 0#var.std_t_phi #standard deviation of timing noise in state process\n",
    "\n",
    "trials = var.trials #number of runs for Q-learning training phase\n",
    "episodes = var.episodes #maximum number for the length of the trajectory\n",
    "\n",
    "learning_rate = 0.001 #learning_rate for the training phase of Q-learning\n",
    "discount_factor = var.discount_factor #discount factor for the training phase of Q-learning\n",
    "epsilon = var.epsilon\n",
    "\n",
    "actions = var.actions #action space\n",
    "discrete_d = var.discrete_d #list of discrete distances, used for discretization of the distance in state space\n",
    "v_max= var.v_max #maximum allowed velocity\n",
    "discrete_v = var.discrete_v #list of discrete velocities, used for discretization of the velocity in state space\n",
    "discrete_phi_t = var.discrete_phi_t #list of discrete pairs of (phi, t_phi), used for discretization of the (phi, t_phi) in state space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105be0c-c539-4611-a60f-9f2944f56379",
   "metadata": {},
   "source": [
    "Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c412edf-f623-4625-8714-c53dec9b4e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 5457996/20000000 [2:16:08<5:48:55, 694.60it/s]"
     ]
    }
   ],
   "source": [
    "Q_table = np.zeros((len(discrete_d)*len(discrete_v)*len(discrete_phi_t), len(actions))) #initialize the Q-table with zero values\n",
    "np.random.seed()\n",
    "accum_rewards = []\n",
    "for trial in tqdm(range(trials)):\n",
    "\n",
    "    idx_i = np.random.randint(0, Q_table.shape[0], 1) #randomly select a row in Q-table which indicates a discretized state\n",
    "    state = func.map_idx_to_state(idx_i, discrete_d, discrete_v, discrete_phi_t) #find the state corresponding to the idx_i\n",
    "    distance = state[0]\n",
    "    velocity = state[1]\n",
    "    accum_r = 0\n",
    "    for episode in range(episodes):\n",
    "        \n",
    "        if distance<0: #if the vehicle passed the intersection\n",
    "            break\n",
    "            \n",
    "        action, action_idx = func.action_selection(Q_table[idx_i], velocity, actions, epsilon, v_max,1) #select the action based on Q-table with epsilon-greedy approach\n",
    "        q = Q_table[idx_i, action_idx] #Q-value of the state and the selected action\n",
    "        \n",
    "        state_new = func.update_state(state, action, delta_t, phi_to_T_dict, phi_to_next_phi_dict, std_d, std_v, std_t_phi,1)#update the state based on the selected action\n",
    "        idx_i_new = func.map_state_to_idx(state_new, discrete_d, discrete_v, discrete_phi_t, T_Y, T_R, phi_prev_phi_dict)#index of the updated state in Q-table\n",
    "        distance = state_new[0]\n",
    "        velocity = state_new[1]\n",
    "        phi = state_new[2]\n",
    "        t_phi = state_new[3]\n",
    "        \n",
    "        reward = func.reward_function(distance, velocity, phi, t_phi, v_max, T_Y) #reward of moving to the new state\n",
    "\n",
    "        td = func.TD_function(reward, discount_factor, Q_table[idx_i_new], q) #td term\n",
    "        \n",
    "        q = q + learning_rate*td #update q-value\n",
    "        Q_table[idx_i,action_idx] = q #update q-value in Q-table\n",
    "        \n",
    "        idx_i = idx_i_new\n",
    "        state = state_new\n",
    "\n",
    "with open('Q_table_noise_0.5_0.25_0.npy','wb') as f:\n",
    "    np.save(f, Q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3161b-7656-4e5b-942c-39cc05a879b1",
   "metadata": {},
   "source": [
    "Q-Table Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8dfdc5b-8334-4e4b-9230-a11676f697ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-zero elements in Qtable:0.8906512605042017\n"
     ]
    }
   ],
   "source": [
    "with open('Q_table_noise_0.5_0.25_0.npy','rb') as f:\n",
    "    Q_table = np.load(f)\n",
    "print(f'Percentage of non-zero elements in Qtable:{len(Q_table[Q_table!=0])/(Q_table.shape[0]*Q_table.shape[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbf243-eb00-4932-84d4-f21bd60f2adb",
   "metadata": {},
   "source": [
    "Test Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae55dcef-55f7-4417-815d-bbdfe9985ae7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State\n",
      "(90.55001067682015, 12.032548969195476, 'Y', 1)\n",
      "\n",
      "state: (90.55001067682015, 12.032548969195476, 'Y', 1)\n",
      "Q_table for this state:[-0.5223302  -0.48154721 -0.06841143 -0.49871669 -0.48365505 -0.48111337\n",
      " -0.48036667]\n",
      "action: -1\n",
      "\n",
      "state: (81.31305954792794, 11.558205959770374, 'Y', 2)\n",
      "Q_table for this state:[ 3.52633125 -0.52395344 -0.56158144 -0.53785171 -0.67747086 -0.57537215\n",
      " -0.5268102 ]\n",
      "action: -3\n",
      "\n",
      "state: (71.37711719093248, 10.960503660204338, 'Y', 3)\n",
      "Q_table for this state:[-0.42950685 -0.43544475 -0.45464775  8.70276134 -0.51050754 -0.46171831\n",
      "  0.53702861]\n",
      "action: 0\n",
      "\n",
      "state: (60.759659790174744, 11.074092041163508, 'Y', 4)\n",
      "Q_table for this state:[24.60873898 -0.42617818 -0.52069574  0.75222118  1.55062264 -0.44776428\n",
      " -0.64472918]\n",
      "action: -3\n",
      "\n",
      "state: (51.830212684261596, 6.749197457648314, 'R', 1)\n",
      "Q_table for this state:[ 2.68762477 56.61098997  4.7861571  -0.61331505 -0.64639659 14.18942982\n",
      " -0.60704195]\n",
      "action: -2\n",
      "\n",
      "state: (47.0739409605469, 3.3272784590704276, 'R', 2)\n",
      "Q_table for this state:[-0.28305311  7.33799968 -0.53180749 67.44256292 -0.48159477 12.56021048\n",
      "  0.45250404]\n",
      "action: 0\n",
      "\n",
      "state: (44.300794759643566, 1.4635953785340292, 'R', 3)\n",
      "Q_table for this state:[ 3.36555171  2.9933457   3.45725727 -0.58821423 57.22473726 -0.50289315\n",
      " -0.4686475 ]\n",
      "action: 1\n",
      "\n",
      "state: (42.611008845098794, 2.6311714486253073, 'R', 4)\n",
      "Q_table for this state:[-1.52018995e-01 -8.85245193e-02 -3.73182486e-01 -3.39902779e-01\n",
      "  1.04177948e+01  2.96841499e-01  1.06021428e+02]\n",
      "action: 3\n",
      "\n",
      "state: (37.48489672293158, 5.755850647601514, 'R', 5)\n",
      "Q_table for this state:[ 40.76816067 100.30022203  32.99678885  34.9323494    3.32058663\n",
      "  34.70386939  -0.21717017]\n",
      "action: -2\n",
      "\n",
      "state: (32.558403042299474, 3.364974495275682, 'R', 6)\n",
      "Q_table for this state:[-3.35526315e-01  6.71642193e+00  3.77627555e-01  3.10810346e-02\n",
      "  1.18890357e+02  3.82653135e+00  1.05207162e+01]\n",
      "action: 1\n",
      "\n",
      "state: (28.326494847386737, 5.755489643613531, 'R', 7)\n",
      "Q_table for this state:[1.66845229e+01 2.43426355e+01 1.09545065e+01 2.11247275e-02\n",
      " 4.60550686e+01 4.74491575e+01 1.14876245e+02]\n",
      "action: 3\n",
      "\n",
      "state: (21.22751334777185, 9.287243564051243, 'R', 8)\n",
      "Q_table for this state:[ 74.13074518  51.02117007  63.53206238  62.26607111 116.8102739\n",
      "  41.76004589  10.58163198]\n",
      "action: 1\n",
      "\n",
      "state: (11.804912511162401, 10.608996004151207, 'R', 9)\n",
      "Q_table for this state:[ 37.1517483  -27.72728625   1.21700831 -17.69286857 -40.42928757\n",
      " -12.0518048   11.90219801]\n",
      "action: -3\n",
      "\n",
      "state: (1.6484381406578046, 8.584782302451266, 'R', 10)\n",
      "Q_table for this state:[  9.9        127.61621604   0.           0.           9.9\n",
      "  18.81         0.        ]\n",
      "action: -2\n",
      "\n",
      "Final State\n",
      "\u001b[32m(-5.273635927753013, 7.118716359291359, 'G', 1)\u001b[0m\n",
      "******************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = (90.55001067682015, 12.032548969195476, 'Y', 1)\n",
    "print('Initial State')\n",
    "print(state)\n",
    "print()\n",
    "idx_i = func.map_state_to_idx(state, discrete_d, discrete_v, discrete_phi_t, T_Y, T_R, phi_prev_phi_dict)\n",
    "mapped_state = func.map_idx_to_state(idx_i, discrete_d, discrete_v, discrete_phi_t)\n",
    "distance = state[0]\n",
    "\n",
    "while (distance>0):\n",
    "    print(f'state: {state}')\n",
    "    \n",
    "    action, action_idx = func.action_selection(Q_table[idx_i], actions, 0)\n",
    "    \n",
    "    print(f'Q_table for this state:{Q_table[idx_i]}')\n",
    "    print(f'action: {action}\\n')\n",
    "\n",
    "    state_new = func.update_state(state, action, delta_t, phi_to_T_dict, phi_to_next_phi_dict, std_d, std_v, std_t_phi)\n",
    "    idx_i_new = func.map_state_to_idx(state_new, discrete_d, discrete_v, discrete_phi_t, T_Y, T_R, phi_prev_phi_dict)\n",
    "    distance = state_new[0]\n",
    "\n",
    "    state=state_new\n",
    "    idx_i=idx_i_new\n",
    "\n",
    "print('Final State')\n",
    "if state[2]=='R':\n",
    "    print(f\"\\x1b[31m{state}\\x1b[0m\")\n",
    "\n",
    "elif state[2]=='G':\n",
    "    print(f\"\\x1b[32m{state}\\x1b[0m\")\n",
    "else:\n",
    "    print(f\"\\x1b[33m{state}\\x1b[0m\")\n",
    "#     print(Q_table[idx_i]) \n",
    "print('******************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96945d-371f-4316-8838-9d0beb24e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c953d-ce39-4c5b-a4ed-f0aa97608c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
